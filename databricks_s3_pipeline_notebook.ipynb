{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3904fa7-e084-4ba5-972a-5c1952954473",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REDACTED]\n[REDACTED]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AWS_ACCESS_KEY_ID = dbutils.secrets.get(scope = \"aws\", key = \"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = dbutils.secrets.get(scope = \"aws\", key = \"AWS_SECRET_ACCESS_KEY\")\n",
    "print(AWS_ACCESS_KEY_ID)\n",
    "print(AWS_SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "429ac0ed-666f-4e6c-9d8d-a8e6c5faa519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3aurl = \"s3a://{}:{}@{}\".format(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,\"vamsee-spark-io/raw/ibm_hr_attrition.csv\")\n",
    "#s3url = \"s3://vamsee-spark-io/source_data/ibm_hr_attrition.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69549b11-7c51-47cd-9dae-05287ec97c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Age: string (nullable = true)\n |-- Attrition: string (nullable = true)\n |-- BusinessTravel: string (nullable = true)\n |-- DailyRate: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- DistanceFromHome: string (nullable = true)\n |-- Education: string (nullable = true)\n |-- EducationField: string (nullable = true)\n |-- EmployeeCount: string (nullable = true)\n |-- EmployeeNumber: string (nullable = true)\n |-- EnvironmentSatisfaction: string (nullable = true)\n |-- Gender: string (nullable = true)\n |-- HourlyRate: string (nullable = true)\n |-- JobInvolvement: string (nullable = true)\n |-- JobLevel: string (nullable = true)\n |-- JobRole: string (nullable = true)\n |-- JobSatisfaction: string (nullable = true)\n |-- MaritalStatus: string (nullable = true)\n |-- MonthlyIncome: string (nullable = true)\n |-- MonthlyRate: string (nullable = true)\n |-- NumCompaniesWorked: string (nullable = true)\n |-- Over18: string (nullable = true)\n |-- OverTime: string (nullable = true)\n |-- PercentSalaryHike: string (nullable = true)\n |-- PerformanceRating: string (nullable = true)\n |-- RelationshipSatisfaction: string (nullable = true)\n |-- StandardHours: string (nullable = true)\n |-- StockOptionLevel: string (nullable = true)\n |-- TotalWorkingYears: string (nullable = true)\n |-- TrainingTimesLastYear: string (nullable = true)\n |-- WorkLifeBalance: string (nullable = true)\n |-- YearsAtCompany: string (nullable = true)\n |-- YearsInCurrentRole: string (nullable = true)\n |-- YearsSinceLastPromotion: string (nullable = true)\n |-- YearsWithCurrManager: string (nullable = true)\n\n+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n|Age|Attrition|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|\n+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n| 41|      Yes|    Travel_Rarely|     1102|               Sales|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|     Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n| 49|       No|Travel_Frequently|      279|Research & Develo...|               8|        1| Life Sciences|            1|             2|                      3|  Male|        61|             2|       2|  Research Scientist|              2|      Married|         5130|      24907|                 1|     Y|      No|               23|                4|                       4|           80|               1|               10|                    3|              3|            10|                 7|                      1|                   7|\n| 37|      Yes|    Travel_Rarely|     1373|Research & Develo...|               2|        2|         Other|            1|             4|                      4|  Male|        92|             2|       1|Laboratory Techni...|              3|       Single|         2090|       2396|                 6|     Y|     Yes|               15|                3|                       2|           80|               0|                7|                    3|              3|             0|                 0|                      0|                   0|\n| 33|       No|Travel_Frequently|     1392|Research & Develo...|               3|        4| Life Sciences|            1|             5|                      4|Female|        56|             3|       1|  Research Scientist|              3|      Married|         2909|      23159|                 1|     Y|     Yes|               11|                3|                       3|           80|               0|                8|                    3|              3|             8|                 7|                      3|                   0|\n| 27|       No|    Travel_Rarely|      591|Research & Develo...|               2|        1|       Medical|            1|             7|                      1|  Male|        40|             3|       1|Laboratory Techni...|              2|      Married|         3468|      16632|                 9|     Y|      No|               12|                3|                       4|           80|               1|                6|                    3|              3|             2|                 2|                      2|                   2|\n+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_preview = spark.read.option(\"header\", \"true\").csv(s3aurl)\n",
    "\n",
    "# Show the inferred schema\n",
    "df_preview.printSchema()\n",
    "\n",
    "# Display a few rows\n",
    "df_preview.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef372199-b459-40f8-8892-4f789074a9e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd0ca12f-bbde-4173-a60d-523017f5af6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3outurl = \"s3a://{}:{}@{}\".format(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,\"vamsee-spark-io/bronze/\")\n",
    "df_preview.coalesce(1).write.mode(\"append\").format(\"delta\").option(\"header\", \"true\").save(s3outurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8260cbbd-3106-405f-b192-d44f3e321e26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a58a95e0-e8b4-458d-afc5-e2c6140175d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "# 1) Read Bronze Delta\n",
    "bronze_path = \"s3a://{}:{}@{}\".format(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,\"vamsee-spark-io/bronze/\")\n",
    "bronze = spark.read.format(\"delta\").load(bronze_path)\n",
    "\n",
    "# 2) Standardize schema & strings\n",
    "# (Adjust casts to match your CSV; these are common in the IBM HR dataset)\n",
    "silver = (\n",
    "    bronze\n",
    "    # trim string columns\n",
    "    .select(*[\n",
    "        F.trim(c).alias(c) if t == \"string\" else F.col(c)\n",
    "        for c, t in bronze.dtypes\n",
    "    ])\n",
    "    # cast numerics that sometimes come as strings\n",
    "    .withColumn(\"Age\", F.col(\"Age\").cast(\"int\"))\n",
    "    .withColumn(\"MonthlyIncome\", F.col(\"MonthlyIncome\").cast(\"int\"))\n",
    "    .withColumn(\"DistanceFromHome\", F.col(\"DistanceFromHome\").cast(\"int\"))\n",
    "    .withColumn(\"YearsAtCompany\", F.col(\"YearsAtCompany\").cast(\"int\"))\n",
    "    .withColumn(\"JobSatisfaction\", F.col(\"JobSatisfaction\").cast(\"int\"))\n",
    "    .withColumn(\"EnvironmentSatisfaction\", F.col(\"EnvironmentSatisfaction\").cast(\"int\"))\n",
    "    .withColumn(\"WorkLifeBalance\", F.col(\"WorkLifeBalance\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "# 3) Normalize categorical values (consistent case)\n",
    "to_title = [\"Department\",\"JobRole\",\"BusinessTravel\",\"EducationField\",\"MaritalStatus\"]\n",
    "for c in to_title:\n",
    "    if c in silver.columns:\n",
    "        silver = silver.withColumn(c, F.initcap(F.col(c)))\n",
    "\n",
    "# 4) Deduplicate on EmployeeNumber (keep latest by ingest_ts if present)\n",
    "if \"ingest_ts\" in silver.columns:\n",
    "    windowed = (silver\n",
    "        .withColumn(\"_rn\", F.row_number().over(\n",
    "            Window.partitionBy(\"EmployeeNumber\").orderBy(F.col(\"ingest_ts\").desc_nulls_last())\n",
    "        ))\n",
    "        .filter(F.col(\"_rn\")==1)\n",
    "        .drop(\"_rn\")\n",
    "    )\n",
    "    silver = windowed\n",
    "else:\n",
    "    silver = silver.dropDuplicates([\"EmployeeNumber\"])\n",
    "\n",
    "# 5) Derived columns\n",
    "silver = (\n",
    "    silver\n",
    "    .withColumn(\"AttritionFlag\", F.when(F.col(\"Attrition\")==\"Yes\", F.lit(1)).otherwise(F.lit(0)))\n",
    "    .withColumn(\"OverTimeFlag\", F.when(F.col(\"OverTime\")==\"Yes\", F.lit(1)).otherwise(F.lit(0)))\n",
    "    .withColumn(\"TenureYears\", F.col(\"YearsAtCompany\").cast(\"double\"))\n",
    "    .withColumn(\n",
    "        \"AgeBand\",\n",
    "        F.when(F.col(\"Age\") < 26, \"18-25\")\n",
    "         .when(F.col(\"Age\") < 36, \"26-35\")\n",
    "         .when(F.col(\"Age\") < 46, \"36-45\")\n",
    "         .otherwise(\"46+\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 6) Simple Data Quality checks (fail fast if something’s off)\n",
    "assert silver.count() > 0, \"DQ FAIL: no rows after cleaning\"\n",
    "required = [\"EmployeeNumber\",\"Department\",\"JobRole\",\"Attrition\"]\n",
    "for c in required:\n",
    "    assert silver.filter(F.col(c).isNull() | (F.col(c)==\"\")).count() == 0, f\"DQ FAIL: null/blank in {c}\"\n",
    "\n",
    "# Optional: validate categories you care about\n",
    "allowed_overtime = {\"Yes\",\"No\"}\n",
    "if \"OverTime\" in silver.columns:\n",
    "    bad = silver.filter(~F.col(\"OverTime\").isin(list(allowed_overtime))).count()\n",
    "    assert bad == 0, f\"DQ FAIL: unexpected OverTime values\"\n",
    "\n",
    "# 7) Write Silver as Delta back to S3\n",
    "# (Use coalesce/repartition to control small files if you want)\n",
    "silver_path = \"s3a://{}:{}@{}\".format(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,\"vamsee-spark-io/silver/\")\n",
    "(silver\n",
    " .repartition(1)            # small demo; for real data pick a sensible number\n",
    " .write\n",
    " .format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"overwriteSchema\",\"true\")\n",
    " .save(silver_path)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af188829-45c7-4b8f-925c-e46bd35b3d6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "477f8015-d38b-4326-a10c-4293eafb66b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 03_aggregate_gold.py\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ---------- Params ----------\n",
    "dbutils.widgets.text(\"bucket\", \"vamsee-spark-io\")\n",
    "bucket = dbutils.widgets.get(\"bucket\")\n",
    "\n",
    "silver_path = \"s3a://{}:{}@{}\".format(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,\"vamsee-spark-io/silver/\")\n",
    "gold_base   = \"s3a://{}:{}@{}\".format(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,\"vamsee-spark-io/gold/\")\n",
    "reports     = \"s3a://{}:{}@{}\".format(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,\"vamsee-spark-io/reports/\")\n",
    "\n",
    "silver = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "# ---------- Core KPI summary (single row) ----------\n",
    "kpi = (\n",
    "    silver.agg(\n",
    "        F.count(\"*\").alias(\"employees\"),\n",
    "        F.mean(\"AttritionFlag\").alias(\"attrition_rate\"),\n",
    "        F.mean(\"OverTimeFlag\").alias(\"overtime_share\"),\n",
    "        F.avg(\"MonthlyIncome\").alias(\"avg_monthly_income\"),\n",
    "        F.avg(\"JobSatisfaction\").alias(\"avg_job_satisfaction\")\n",
    "    )\n",
    "    .withColumn(\"attrition_rate\", F.round(\"attrition_rate\", 4))\n",
    "    .withColumn(\"overtime_share\", F.round(\"overtime_share\", 4))\n",
    "    .withColumn(\"avg_monthly_income\", F.round(\"avg_monthly_income\", 2))\n",
    "    .withColumn(\"avg_job_satisfaction\", F.round(\"avg_job_satisfaction\", 2))\n",
    ")\n",
    "kpi_path = f\"{gold_base}/kpi_summary\"\n",
    "kpi.write.format(\"delta\").mode(\"overwrite\").save(kpi_path)\n",
    "\n",
    "# ---------- Helper to compute attrition rate rollups ----------\n",
    "def rate(df, group_cols):\n",
    "    return (\n",
    "        df.groupBy(*group_cols)\n",
    "          .agg(F.count(\"*\").alias(\"employees\"),\n",
    "               F.mean(\"AttritionFlag\").alias(\"attrition_rate\"))\n",
    "          .withColumn(\"attrition_rate\", F.round(\"attrition_rate\", 4))\n",
    "          .orderBy(*group_cols)\n",
    "    )\n",
    "\n",
    "# ---------- Rollups ----------\n",
    "by_dept   = rate(silver, [\"Department\"])\n",
    "by_role   = rate(silver, [\"Department\", \"JobRole\"])\n",
    "by_age    = rate(silver, [\"AgeBand\"]) if \"AgeBand\" in silver.columns else rate(silver, [\"Age\"])\n",
    "by_ot     = rate(silver, [\"OverTimeFlag\"])\n",
    "\n",
    "# If you created TenureBand in Silver, prefer that. Otherwise YearsAtCompany.\n",
    "group_tenure = [\"TenureBand\"] if \"TenureBand\" in silver.columns else [\"YearsAtCompany\"]\n",
    "by_tenure = rate(silver, group_tenure)\n",
    "\n",
    "by_dept.write .format(\"delta\").mode(\"overwrite\").save(f\"{gold_base}/attrition_by_department\")\n",
    "by_role.write .format(\"delta\").mode(\"overwrite\").save(f\"{gold_base}/attrition_by_dept_role\")\n",
    "by_age.write  .format(\"delta\").mode(\"overwrite\").save(f\"{gold_base}/attrition_by_age\")\n",
    "by_ot.write   .format(\"delta\").mode(\"overwrite\").save(f\"{gold_base}/attrition_by_overtime\")\n",
    "by_tenure.write.format(\"delta\").mode(\"overwrite\").save(f\"{gold_base}/attrition_by_tenure\")\n",
    "\n",
    "# ---------- Income & satisfaction insights ----------\n",
    "income_by_role = (\n",
    "    silver.groupBy(\"JobRole\")\n",
    "          .agg(\n",
    "              F.count(\"*\").alias(\"employees\"),\n",
    "              F.avg(\"MonthlyIncome\").alias(\"avg_income\"),\n",
    "              F.expr(\"percentile_approx(MonthlyIncome, 0.5)\").alias(\"median_income\")\n",
    "          )\n",
    "          .withColumn(\"avg_income\", F.round(\"avg_income\", 2))\n",
    "          .orderBy(F.desc(\"avg_income\"))\n",
    ")\n",
    "income_by_role.write.format(\"delta\").mode(\"overwrite\").save(f\"{gold_base}/income_by_role\")\n",
    "\n",
    "sat_vs_attr = (\n",
    "    silver.groupBy(\"JobSatisfaction\")\n",
    "          .agg(\n",
    "              F.count(\"*\").alias(\"employees\"),\n",
    "              F.mean(\"AttritionFlag\").alias(\"attrition_rate\")\n",
    "          )\n",
    "          .withColumn(\"attrition_rate\", F.round(\"attrition_rate\", 4))\n",
    "          .orderBy(\"JobSatisfaction\")\n",
    ")\n",
    "sat_vs_attr.write.format(\"delta\").mode(\"overwrite\").save(f\"{gold_base}/attrition_by_jobsatisfaction\")\n",
    "\n",
    "# ---------- BI-friendly CSV exports (optional) ----------\n",
    "(by_dept.coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"header\", True)\n",
    "    .csv(f\"{reports}/attrition_by_department_csv\"))\n",
    "\n",
    "(income_by_role.coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"header\", True)\n",
    "    .csv(f\"{reports}/income_by_role_csv\"))\n",
    "\n",
    "(kpi.coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"header\", True)\n",
    "    .csv(f\"{reports}/kpi_summary_csv\"))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark-testing",
   "widgets": {
    "bucket": {
     "currentValue": "vamsee-spark-io",
     "nuid": "a4923030-aff0-44ec-8421-37acf5a78638",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "vamsee-spark-io",
      "label": null,
      "name": "bucket",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "vamsee-spark-io",
      "label": null,
      "name": "bucket",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}